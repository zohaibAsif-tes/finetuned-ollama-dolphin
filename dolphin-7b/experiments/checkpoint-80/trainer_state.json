{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 64.0,
  "eval_steps": 500,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.8,
      "grad_norm": 4.286828517913818,
      "learning_rate": 5e-05,
      "loss": 2.644,
      "step": 1
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.7821550369262695,
      "learning_rate": 0.0001,
      "loss": 2.2585,
      "step": 2
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.8391830921173096,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.5743,
      "step": 3
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.4076955318450928,
      "learning_rate": 0.0002,
      "loss": 2.3704,
      "step": 4
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.999950647354126,
      "learning_rate": 0.0001999145758387301,
      "loss": 2.2432,
      "step": 5
    },
    {
      "epoch": 4.8,
      "grad_norm": 2.5485408306121826,
      "learning_rate": 0.000199658449300667,
      "loss": 2.1394,
      "step": 6
    },
    {
      "epoch": 5.6,
      "grad_norm": 2.0038065910339355,
      "learning_rate": 0.0001992320579737045,
      "loss": 1.9153,
      "step": 7
    },
    {
      "epoch": 6.4,
      "grad_norm": 2.8435423374176025,
      "learning_rate": 0.00019863613034027224,
      "loss": 1.742,
      "step": 8
    },
    {
      "epoch": 7.2,
      "grad_norm": 2.8677871227264404,
      "learning_rate": 0.00019787168453273544,
      "loss": 1.7646,
      "step": 9
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.4459474086761475,
      "learning_rate": 0.00019694002659393305,
      "loss": 1.4472,
      "step": 10
    },
    {
      "epoch": 8.8,
      "grad_norm": 2.7884318828582764,
      "learning_rate": 0.0001958427482458253,
      "loss": 1.3718,
      "step": 11
    },
    {
      "epoch": 9.6,
      "grad_norm": 3.9229233264923096,
      "learning_rate": 0.00019458172417006347,
      "loss": 1.2152,
      "step": 12
    },
    {
      "epoch": 10.4,
      "grad_norm": 3.3864152431488037,
      "learning_rate": 0.0001931591088051279,
      "loss": 0.9812,
      "step": 13
    },
    {
      "epoch": 11.2,
      "grad_norm": 7.162324905395508,
      "learning_rate": 0.00019157733266550575,
      "loss": 0.8882,
      "step": 14
    },
    {
      "epoch": 12.0,
      "grad_norm": 5.065024375915527,
      "learning_rate": 0.0001898390981891979,
      "loss": 0.746,
      "step": 15
    },
    {
      "epoch": 12.8,
      "grad_norm": 4.335855007171631,
      "learning_rate": 0.0001879473751206489,
      "loss": 0.5937,
      "step": 16
    },
    {
      "epoch": 13.6,
      "grad_norm": 4.3511271476745605,
      "learning_rate": 0.00018590539543698854,
      "loss": 0.4911,
      "step": 17
    },
    {
      "epoch": 14.4,
      "grad_norm": 4.803386688232422,
      "learning_rate": 0.00018371664782625287,
      "loss": 0.4143,
      "step": 18
    },
    {
      "epoch": 15.2,
      "grad_norm": 2.7419142723083496,
      "learning_rate": 0.0001813848717270195,
      "loss": 0.3233,
      "step": 19
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.5521678924560547,
      "learning_rate": 0.00017891405093963938,
      "loss": 0.2789,
      "step": 20
    },
    {
      "epoch": 16.8,
      "grad_norm": 1.485710859298706,
      "learning_rate": 0.00017630840681998066,
      "loss": 0.2319,
      "step": 21
    },
    {
      "epoch": 17.6,
      "grad_norm": 1.5067850351333618,
      "learning_rate": 0.00017357239106731317,
      "loss": 0.1687,
      "step": 22
    },
    {
      "epoch": 18.4,
      "grad_norm": 2.502915859222412,
      "learning_rate": 0.00017071067811865476,
      "loss": 0.1678,
      "step": 23
    },
    {
      "epoch": 19.2,
      "grad_norm": 2.718841075897217,
      "learning_rate": 0.00016772815716257412,
      "loss": 0.1244,
      "step": 24
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.9253458380699158,
      "learning_rate": 0.00016462992378609407,
      "loss": 0.1188,
      "step": 25
    },
    {
      "epoch": 20.8,
      "grad_norm": 0.5319721698760986,
      "learning_rate": 0.0001614212712689668,
      "loss": 0.1048,
      "step": 26
    },
    {
      "epoch": 21.6,
      "grad_norm": 0.41321900486946106,
      "learning_rate": 0.00015810768154019385,
      "loss": 0.0997,
      "step": 27
    },
    {
      "epoch": 22.4,
      "grad_norm": 1.3821536302566528,
      "learning_rate": 0.00015469481581224272,
      "loss": 0.0847,
      "step": 28
    },
    {
      "epoch": 23.2,
      "grad_norm": 0.3890570104122162,
      "learning_rate": 0.00015118850490896012,
      "loss": 0.1009,
      "step": 29
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.5786623954772949,
      "learning_rate": 0.00014759473930370736,
      "loss": 0.0845,
      "step": 30
    },
    {
      "epoch": 24.8,
      "grad_norm": 0.29866823554039,
      "learning_rate": 0.00014391965888473703,
      "loss": 0.0848,
      "step": 31
    },
    {
      "epoch": 25.6,
      "grad_norm": 0.7896801829338074,
      "learning_rate": 0.00014016954246529696,
      "loss": 0.0764,
      "step": 32
    },
    {
      "epoch": 26.4,
      "grad_norm": 0.1534038782119751,
      "learning_rate": 0.00013635079705638298,
      "loss": 0.0735,
      "step": 33
    },
    {
      "epoch": 27.2,
      "grad_norm": 0.13791312277317047,
      "learning_rate": 0.00013246994692046836,
      "loss": 0.0694,
      "step": 34
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.09676407277584076,
      "learning_rate": 0.00012853362242491053,
      "loss": 0.0725,
      "step": 35
    },
    {
      "epoch": 28.8,
      "grad_norm": 0.1767149120569229,
      "learning_rate": 0.00012454854871407994,
      "loss": 0.0721,
      "step": 36
    },
    {
      "epoch": 29.6,
      "grad_norm": 0.07412703335285187,
      "learning_rate": 0.00012052153421956342,
      "loss": 0.0707,
      "step": 37
    },
    {
      "epoch": 30.4,
      "grad_norm": 0.08281602710485458,
      "learning_rate": 0.00011645945902807341,
      "loss": 0.0714,
      "step": 38
    },
    {
      "epoch": 31.2,
      "grad_norm": 0.0930330902338028,
      "learning_rate": 0.00011236926312693479,
      "loss": 0.0691,
      "step": 39
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.08907640725374222,
      "learning_rate": 0.00010825793454723325,
      "loss": 0.0697,
      "step": 40
    },
    {
      "epoch": 32.8,
      "grad_norm": 0.0758068710565567,
      "learning_rate": 0.00010413249742488131,
      "loss": 0.0712,
      "step": 41
    },
    {
      "epoch": 33.6,
      "grad_norm": 0.09346891939640045,
      "learning_rate": 0.0001,
      "loss": 0.0678,
      "step": 42
    },
    {
      "epoch": 34.4,
      "grad_norm": 0.09323513507843018,
      "learning_rate": 9.586750257511867e-05,
      "loss": 0.071,
      "step": 43
    },
    {
      "epoch": 35.2,
      "grad_norm": 0.10266996920108795,
      "learning_rate": 9.174206545276677e-05,
      "loss": 0.0672,
      "step": 44
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.10477403551340103,
      "learning_rate": 8.763073687306524e-05,
      "loss": 0.0676,
      "step": 45
    },
    {
      "epoch": 36.8,
      "grad_norm": 0.11240469664335251,
      "learning_rate": 8.35405409719266e-05,
      "loss": 0.0657,
      "step": 46
    },
    {
      "epoch": 37.6,
      "grad_norm": 0.10459183156490326,
      "learning_rate": 7.947846578043659e-05,
      "loss": 0.0683,
      "step": 47
    },
    {
      "epoch": 38.4,
      "grad_norm": 0.11674374341964722,
      "learning_rate": 7.54514512859201e-05,
      "loss": 0.0639,
      "step": 48
    },
    {
      "epoch": 39.2,
      "grad_norm": 0.10448677837848663,
      "learning_rate": 7.146637757508949e-05,
      "loss": 0.0659,
      "step": 49
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.11542484164237976,
      "learning_rate": 6.753005307953167e-05,
      "loss": 0.0631,
      "step": 50
    },
    {
      "epoch": 40.8,
      "grad_norm": 0.12091479450464249,
      "learning_rate": 6.3649202943617e-05,
      "loss": 0.0627,
      "step": 51
    },
    {
      "epoch": 41.6,
      "grad_norm": 0.09729874134063721,
      "learning_rate": 5.983045753470308e-05,
      "loss": 0.064,
      "step": 52
    },
    {
      "epoch": 42.4,
      "grad_norm": 0.09131547808647156,
      "learning_rate": 5.608034111526298e-05,
      "loss": 0.0638,
      "step": 53
    },
    {
      "epoch": 43.2,
      "grad_norm": 0.15506671369075775,
      "learning_rate": 5.240526069629265e-05,
      "loss": 0.0567,
      "step": 54
    },
    {
      "epoch": 44.0,
      "grad_norm": 0.08184519410133362,
      "learning_rate": 4.8811495091039926e-05,
      "loss": 0.062,
      "step": 55
    },
    {
      "epoch": 44.8,
      "grad_norm": 0.09832512587308884,
      "learning_rate": 4.530518418775733e-05,
      "loss": 0.0586,
      "step": 56
    },
    {
      "epoch": 45.6,
      "grad_norm": 0.0759834423661232,
      "learning_rate": 4.189231845980618e-05,
      "loss": 0.0649,
      "step": 57
    },
    {
      "epoch": 46.4,
      "grad_norm": 0.12426086515188217,
      "learning_rate": 3.857872873103322e-05,
      "loss": 0.0543,
      "step": 58
    },
    {
      "epoch": 47.2,
      "grad_norm": 0.0875108391046524,
      "learning_rate": 3.53700762139059e-05,
      "loss": 0.0559,
      "step": 59
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.07335970550775528,
      "learning_rate": 3.227184283742591e-05,
      "loss": 0.0599,
      "step": 60
    },
    {
      "epoch": 48.8,
      "grad_norm": 0.07139481604099274,
      "learning_rate": 2.9289321881345254e-05,
      "loss": 0.0607,
      "step": 61
    },
    {
      "epoch": 49.6,
      "grad_norm": 0.09485951066017151,
      "learning_rate": 2.6427608932686843e-05,
      "loss": 0.0548,
      "step": 62
    },
    {
      "epoch": 50.4,
      "grad_norm": 0.08023224025964737,
      "learning_rate": 2.3691593180019366e-05,
      "loss": 0.0556,
      "step": 63
    },
    {
      "epoch": 51.2,
      "grad_norm": 2.174107551574707,
      "learning_rate": 2.1085949060360654e-05,
      "loss": 0.0604,
      "step": 64
    },
    {
      "epoch": 52.0,
      "grad_norm": 0.07984133809804916,
      "learning_rate": 1.861512827298051e-05,
      "loss": 0.0552,
      "step": 65
    },
    {
      "epoch": 52.8,
      "grad_norm": 0.0785585269331932,
      "learning_rate": 1.6283352173747145e-05,
      "loss": 0.0587,
      "step": 66
    },
    {
      "epoch": 53.6,
      "grad_norm": 0.08855850249528885,
      "learning_rate": 1.4094604563011472e-05,
      "loss": 0.0554,
      "step": 67
    },
    {
      "epoch": 54.4,
      "grad_norm": 0.09559234976768494,
      "learning_rate": 1.2052624879351104e-05,
      "loss": 0.0532,
      "step": 68
    },
    {
      "epoch": 55.2,
      "grad_norm": 0.08378773182630539,
      "learning_rate": 1.0160901810802115e-05,
      "loss": 0.0595,
      "step": 69
    },
    {
      "epoch": 56.0,
      "grad_norm": 0.08252529054880142,
      "learning_rate": 8.422667334494249e-06,
      "loss": 0.0545,
      "step": 70
    },
    {
      "epoch": 56.8,
      "grad_norm": 0.082563616335392,
      "learning_rate": 6.840891194872112e-06,
      "loss": 0.058,
      "step": 71
    },
    {
      "epoch": 57.6,
      "grad_norm": 0.09303425997495651,
      "learning_rate": 5.418275829936537e-06,
      "loss": 0.0555,
      "step": 72
    },
    {
      "epoch": 58.4,
      "grad_norm": 0.07965286076068878,
      "learning_rate": 4.1572517541747294e-06,
      "loss": 0.0543,
      "step": 73
    },
    {
      "epoch": 59.2,
      "grad_norm": 0.08164447546005249,
      "learning_rate": 3.059973406066963e-06,
      "loss": 0.0541,
      "step": 74
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.08262353390455246,
      "learning_rate": 2.128315467264552e-06,
      "loss": 0.058,
      "step": 75
    },
    {
      "epoch": 60.8,
      "grad_norm": 0.08069657534360886,
      "learning_rate": 1.3638696597277679e-06,
      "loss": 0.0545,
      "step": 76
    },
    {
      "epoch": 61.6,
      "grad_norm": 0.10825390368700027,
      "learning_rate": 7.679420262954984e-07,
      "loss": 0.0629,
      "step": 77
    },
    {
      "epoch": 62.4,
      "grad_norm": 0.08066842705011368,
      "learning_rate": 3.415506993330153e-07,
      "loss": 0.0531,
      "step": 78
    },
    {
      "epoch": 63.2,
      "grad_norm": 0.10297016054391861,
      "learning_rate": 8.542416126989805e-08,
      "loss": 0.0545,
      "step": 79
    },
    {
      "epoch": 64.0,
      "grad_norm": 0.08053886890411377,
      "learning_rate": 0.0,
      "loss": 0.0538,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 80,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 80,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1749190862438400.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
